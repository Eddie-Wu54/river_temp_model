---
title: "Master temperature model comparison"
author: "Eddie Wu"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This R markdown file is used to 

1. Import and clean global water temperature model

2. Fit three candidate models on training and testing data for different time scales.

3. Compare the weekly performance of a non-linear model and the global futureStreams river temperature model on a different seasonal scales (spring, summer, fall, annual).

**All model metrics are calculated on a weekly scale!!!**


```{r library, warning=FALSE, message=FALSE}
library(dplyr)
library(tidyverse)
library(nlme)
library(xts)
library(zoo)
library(lubridate)
library(drc)
```

```{r functions}
get.traintest <- function(master.df, year.list, fold) {
  
  # create output
  combined_training_list <- vector("list",fold)
  combined_testing_list <- vector("list",fold)
  
  ## Loop 10 folds
  for (f in 1:fold) {
    
    # dataframe to store the sampled years for each location
    dfind = data.frame(location=character(),
                     year=integer(), stringsAsFactors = FALSE)
    dfindt = data.frame(location=character(),
                     year=integer(), stringsAsFactors = FALSE)
    
    for (i in 1:length(year.list)){ # i loops through each location
      smp = year.list[[i]] #train
      if (length(smp)>1){
        indx.train=(sample(smp, 1))
        ytrain=indx.train
      } else if (length(smp)==1){
        indx.train=smp
        ytrain=indx.train
      }
      
      smpt = year.list[[i]][year.list[[i]] != indx.train] #test
      if (length(smpt)>1){
        indx.test=(sample(smpt, 1))
        ytest=indx.test
      } else if (length(smpt)==1){
        indx.test=smpt
        ytest=indx.test
      }
      
      dfind[i,] = c(names(year.list[i]), ytrain)
      dfindt[i,] = c(names(year.list[i]), ytest)
    }
    
    # subset the dataframe
    awf_train <- merge(master.df, dfind, by=c("location", "year"))
    awf_test <- merge(master.df, dfindt, by=c("location", "year"))
      
    combined_training_list[[f]] <- awf_train
    combined_testing_list[[f]] <- awf_test
  }
  return(list(combined_training_list, combined_testing_list))
}
good_year <- function(master.df, dayln) {
  # get table of sample years by location
  yr_out=table(master.df$location, master.df$year)

  # select sample years with more than X days (x=250)
  full_year=list()
  sind=vector()
  cnt=0
  ind=0
  
  for (i in seq_along(loc_seq)){
   rm(ind)
   if (ncol(yr_out)>=1) {
     ind=which(yr_out[row.names(yr_out)==loc_seq[i],]>dayln)
     
     if (length(ind)>0) {
       sind=c(sind,i)
       cnt=cnt+1
       full_year[[cnt]]=colnames(yr_out)[ind]
     }
   }
  }
  full_year=setNames(full_year,loc_seq[sind])
  print(full_year)
}
```



## SECTION 1: Data importing and cleaning

```{r data import}
## Data import
air <- read.csv("tributary air temperatures clean.csv", stringsAsFactors=F)
water <- read.csv("tributary water temperature/water_temperature_d.csv",
                  stringsAsFactors=F)
flow <- read.csv("tributary discharge.csv", stringsAsFactors=F)

# Convert to date format
air$date <- as.Date(air$date, "%m/%d/%Y")
water$date <- as.Date(water$date, "%m/%d/%Y")
flow$date <- as.Date(flow$date, "%m/%d/%Y")


## Calculate the MEAN airT for US locations
for (i in which(is.na(air$mean_temp))) {
  air$mean_temp <- (air$max_temp + air$min_temp) / 2
}
```

### Data combining

```{r data combine}
## Combine water temperature and discharge
aw <- merge(air, water, by = c("station_name","date"))
awf <- merge(aw, flow, by = c("location","date"))
awf <- awf %>% arrange(location, date)

## Change into factor
awf$location <- as.factor(awf$location)
awf$station_name <- as.factor(awf$station_name)

# Get location sequence
loc_seq=levels(awf$location)


## Check if there are any duplicates
duplicates <- awf %>%
  group_by(location, date) %>%
  filter(n() > 1) # Duplicates should be NA...


## Print the result
table(awf$location)
```

### Check for imputed values

Use a 7-days rolling mean to check for possibly imputed temperatures. If the variance of a certain day's temperature is very close to zero, then it is likely that this particular data is imputed.

```{r impute check}
# make sure that no initial NA values in awf water temperature
which(is.na(awf$temp))

# Need to calculate the rolling mean for each location separately...
for(loc in loc_seq) {
  sub <- awf[awf$location == loc,]
  sub$rolling_mean <- rollmean(sub$temp, k = 7, fill = NA, align = "right")
  awf[awf$location == loc, "rolling_mean"] <- sub$rolling_mean
}

# Calculate variance
awf$variance <- (awf$temp - awf$rolling_mean)^2

# Assign NA when variance is very small
awf$temp[which(awf$variance < 1e-10)] <- NA

# Check results - how many imputed values are in each location
awf %>%
  group_by(location) %>%
  summarise(na_count = sum(is.na(temp)))

```


### Get lagged days

```{r lagged days}
## Get the time lag day variables
awf <- awf %>%
  group_by(location) %>%
  mutate(dmean_1 = lag(mean_temp, 1),
         dmean_2 = lag(mean_temp, 2),
         dmean_3 = lag(mean_temp, 3),
         dmean_4 = lag(mean_temp, 4),
         dmean_5 = lag(mean_temp, 5),
         dflow_1 = lag(flow, 1))


## Get cumulative air temp for past five days
awf <- awf %>% 
  rowwise() %>% 
  mutate(cair = (mean_temp+dmean_1+dmean_2+dmean_3+dmean_4+dmean_5)/6) %>% 
  ungroup()

## Get relative flow
awf <- awf %>% mutate(rqc = (flow - dflow_1)/flow)
```


### Get final master temp dataframe

```{r master temp}
master.temp <- awf[complete.cases(cbind(awf$mean_temp,awf$temp)),] %>% 
  select(location, date, station_name, country,
         year, month = month.x, day = day.x,
         water = temp, air = mean_temp, dmean_1, dmean_2, dmean_3,
         dmean_4, dmean_5, flow, dflow_1, rqc, cair)

master.temp <- master.temp[complete.cases(master.temp[,8:18]),]
```



## SECTION 2: Get training and testing


### Identify good year/month data

We want the seasonal data to be greater than 60 days, annual data (winter removed) more than 180 days.

```{r good years, echo=FALSE}
## Annual (250 days)
fulyear <- good_year(master.annual, 180)


## Seasonal (60 days)
fulspring <- good_year(master.spring, 60)
fulsum <- good_year(master.sum, 60)
fulfall <- good_year(master.fall, 60)
fulwin <- good_year(master.win, 60)
```


### Get training and testing

Similarly, get training and testing for the specific season.

```{r get training and testing, eval=FALSE}
fold = 10

## Get training and testing for annual
annual <- get.traintest(master.annual, fulyear, 10)

combined_training_list <- annual[[1]]
combined_testing_list <- annual[[2]]


## Get training and testing for each season
sum <- get.traintest(master.sum, fulsum, 10)
win <- get.traintest(master.win, fulwin, 10)
spr <- get.traintest(master.spring, fulspring, 10)
fall <- get.traintest(master.fall, fulfall, 10)

combined_training_list_sp <- spr[[1]]
combined_testing_list_sp <- spr[[2]]

combined_training_list_su <- sum[[1]]
combined_testing_list_su <- sum[[2]]

combined_training_list_fa <- fall[[1]]
combined_testing_list_fa <- fall[[2]]

combined_training_list_w <- win[[1]]
combined_testing_list_w <- win[[2]]


## Create a list to store all the combined training and testing lists
grand_training <- list(combined_training_list_sp, combined_training_list_su,
                       combined_training_list_fa, combined_training_list_w,
                       combined_training_list)

grand_testing <- list(combined_testing_list_sp, combined_testing_list_su,
                       combined_testing_list_fa, combined_testing_list_w,
                       combined_testing_list)
```


### Simple get training and testing

```{r get train and test unique}
ytrain = c(2006,2013,2013,2011,2001,2011,2008,2011,2014,2002,2011,2013)
ytest = c(2003,2012,2014,2013,2005,2013,2009,2012,2013,2005,2013,2014)
y = cbind(loc_seq,ytrain,ytest)

current.training <- merge(master.temp, y,
                          by.x = c("location", "year"),
                          by.y = c("loc_seq", "ytrain")) %>% 
  arrange(location, date)

current.testing <- merge(master.temp, y,
                          by.x = c("location", "year"),
                          by.y = c("loc_seq", "ytest")) %>% 
  arrange(location, date)


# breakpoint
current.training <-current.training %>% 
  filter(yday(date)>91 & yday(date)<204)

current.testing <-current.testing %>% 
  filter(yday(date)>91 & yday(date)<204)

ctrl = glsControl(opt='optim')


## dataframe to store all the results
rmse.r <- matrix(NA, ncol=4, nrow=12)
colnames(rmse.r) <- c("linear","seasonal","nonlinear","future")
rownames(rmse.r) <- loc_seq

bias.r <- matrix(NA, ncol=4, nrow=12)
colnames(bias.r) <- c("linear","seasonal","nonlinear","future")
rownames(bias.r) <- loc_seq

nsc.r <- matrix(NA, ncol=4, nrow=12)
colnames(nsc.r) <- c("linear","seasonal","nonlinear","future")
rownames(nsc.r) <- loc_seq


## list to store one of the weekly aggregated water temp
complist <- vector("list",12)
names(complist) <- loc_seq
```



## SECTION 3: REGIONAL model comparison

We now run each of the three models only once.

We run all three candidate models on 12 tributary locations separately. For each location, the model assumption is checked to ensure that the prediction is valid.

**Model predictions are aggregated to weekly scale, and all performance metrics are calculated on a weekly scale to allow comparison to the global model.**


### Linear lag5

```{r linear individual}
## Coefs
coef.lag6 <- matrix(NA, ncol=8, nrow=12)
colnames(coef.lag6) <- c("a","b","c","d","e","f","g","h")
rownames(coef.lag6) <- loc_seq


## Forms
form.locrandom <- water ~ air + dmean_1 + dmean_2 + dmean_3 + dmean_4 + dmean_5 + dmean_6

# For each location
for (loc in loc_seq){
  
  dftrain = current.training[current.training$location == loc,]
  dftest = current.testing[current.testing$location == loc,]
  compare = dftest
  
  # model
  model.ar <- gls(form.locrandom, control = ctrl,
                  na.action = na.omit, data = dftrain,
                  correlation=corAR1())
  compare$preds.ar <- as.vector(predict(model.ar, newdata = dftest))
  compare$week <- ceiling(as.numeric(format(compare$date, "%j"))/7)

  # weekly comparison dataframe
  compare.w <- merge(
    aggregate(preds.ar~week+location,FUN=mean,data=compare,
              na.action=na.omit),
    aggregate(water~week+location,FUN=mean,data=compare,
              na.action=na.omit),all=TRUE) %>% na.omit() %>% 
    arrange(location, week)
  
  complist[[loc]][[1]] <- compare.w
  
  # store in results dataframes
  rmse.r[loc,1]=round(sqrt(mean((compare.w$preds.ar-compare.w$water)^2)),2)
  bias.r[loc,1]=round(mean(compare.w$preds.ar-compare.w$water),2)
  nsc.r[loc,1]=round(1-sum((compare.w$water-compare.w$preds.ar)^2) / sum((compare.w$water-mean(compare.w$water))^2),2)
  
  
  ## assumptions
  plot(model.ar$residuals~model.ar$fitted, main=loc)
  abline(h=0)
  
  
  ## prediction plots - weekly
  
  pl <- ggplot(data=compare.w, aes(x=week))+
          geom_line(aes(x=week, y=water), color = "black")+
          geom_line(aes(x=week, y=preds.ar), color = "blue")+
          ggtitle(paste(
            loc, ": (RMSE:", rmse.r[loc,1], "&", "bias:",
            bias.r[loc,1], ")"))
  print(pl)
  
  
  ## get coef
  for (c in 1:8){coef.lag6[loc,c]=signif(coef(model.ar)[c],2)}
}
```


### Seasonal residual

```{r seasonal individual}
## Coefs
coef.season <- matrix(NA, ncol=6, nrow=12)
colnames(coef.season) <- c("a","b","c","beta1","beta2","beta3")
rownames(coef.season) <- loc_seq


# For each location
for (loc in loc_seq){
  
  dftrain = current.training[current.training$location == loc,]
  dftest = current.testing[current.testing$location == loc,]
  compare <- dftest
  
  # model
  annual.comp <- nls(air ~ a+b*sin(2*pi/365*(yday(date)+t0)),
                   start = list(a=0.05, b=5, t0=-26),
                   data=dftrain)

  # get the air temperature residuals
  res <- as.data.frame(matrix(NA, ncol = 2, 
                            nrow = length(na.omit(dftrain$air))))
  # dataframe to store the residuals
  colnames(res) <- c("res.t", "location")
  res[,"location"] <- na.omit(dftrain$location)
  res[,"res.t"] <- as.vector(residuals(annual.comp))
  res <- res %>% group_by(location) %>%
    mutate(res.t1 = lag(res.t, 1),
           res.t2 = lag(res.t, 2))
  res[,"res.w"] <- residuals(nls(water ~ a+b*sin(2*pi/365*(yday(date)+t0)),
                               start = list(a=0.05, b=5, t0=-26),
                               data = dftrain))

  # get the water temperature residual component
  residual.comp.ar <- gls(res.w ~ res.t + res.t1 + res.t2,
                          correlation = corAR1(),
                          data = res, na.action = na.omit,
                          control = ctrl)
  
  ## TESTING
  # Annual
  preds.annual <- as.data.frame(predict(annual.comp, newdata=dftest))
  preds.annual <- cbind(preds.annual, dftest$location, dftest$date)
  colnames(preds.annual) <- c("preds.annual", "location", "date")

  # Residuals data
  res <- as.data.frame(matrix(NA, ncol = 3, 
                              nrow = length(dftest$air))) #residuals
  colnames(res) <- c("res.t", "location", "date")
  res[,"location"] <- dftest$location
  res[,"date"] <- dftest$date
  res[,"res.t"] <- dftest$air - preds.annual$preds.annual
  res <- res %>% group_by(location) %>%
  mutate(res.t1 = lag(res.t, 1),
         res.t2 = lag(res.t, 2))

  # Residuals predictions
  pres.ar <- predict(residual.comp.ar, newdata=res, na.action=na.omit)
  preds.residuals <- cbind(na.omit(res)[,"location"],
                           na.omit(res)[,"date"], as.data.frame(pres.ar))

  # Combine and add up both components
  p <- merge(preds.annual, preds.residuals, by=c("location","date"))
  p[,"preds.ar"] <- p$preds.annual + p$pres.ar

  compare <- merge(dftest, p, by=c("location","date"))
  compare$week <- ceiling(as.numeric(format(compare$date, "%j"))/7)

  # weekly comparison dataframe
  compare.w <- merge(
    aggregate(preds.ar~week+location,FUN=mean,data=compare,
              na.action=na.omit),
    aggregate(water~week+location,FUN=mean,data=compare,
              na.action=na.omit),all=TRUE) %>% na.omit() %>% 
    arrange(location, week)
  
  complist[[loc]][[2]] <- compare.w
  
  # store in results dataframes
  rmse.r[loc,2]=round(sqrt(mean((compare.w$preds.ar-compare.w$water)^2)),2)
  bias.r[loc,2]=round(mean(compare.w$preds.ar-compare.w$water),2)
  nsc.r[loc,2]=round(1-sum((compare.w$water-compare.w$preds.ar)^2) / sum((compare.w$water-mean(compare.w$water))^2),2)
  
  
  ## assumptions
  plot(residual.comp.ar$residuals~residual.comp.ar$fitted, main=loc)
  abline(h=0)
  

  ## prediction plots
  pl <- ggplot(data=compare.w, aes(x=week))+
          geom_line(aes(x=week, y=water), color = "black")+
          geom_line(aes(x=week, y=preds.ar), color = "blue")+
          ggtitle(paste(
            loc, ": (RMSE:", rmse.r[loc,2], "&", "bias:",
            bias.r[loc,2], ")"))
  print(pl)
  
  ## get coefs
  
  for (c in 1:3){
    coef.season[loc,c]=signif(coef(annual.comp)[c],2)
    coef.season[loc,c+3]=signif(coef(residual.comp.ar)[c+1],2)}
}
```


### Non-linear

```{r non-linear, eval=TRUE, warning=FALSE}
## Coefs
coef.nonl <- matrix(NA, ncol=3, nrow=12)
colnames(coef.nonl) <- c("alpha","beta","gamma")
rownames(coef.nonl) <- loc_seq


# For each location
for (loc in loc_seq){
  
    dftrain = current.training[current.training$location == loc,] %>% 
      rowwise() %>% 
      mutate(cair = mean(c_across(9:15)))
    dftest = current.testing[current.testing$location == loc,] %>% 
      rowwise() %>% 
      mutate(cair = mean(c_across(9:15)))
    compare <- dftest
    
    # coefs
    modelco <- drm(water ~ air, fct = L.3(), data = dftrain)
    co = c(alpha=as.numeric(coef(modelco)[2]),
           beta=as.numeric(coef(modelco)[3]),
           gamma=as.numeric(-coef(modelco)[1]))
  
    
    # model
    model.new <- gnls(water ~ alpha / (1 + exp(gamma * (beta - cair))),
                      data = dftrain, na.action = na.omit,
                      start = co,
                      correlation = corAR1(),
                      control=gnlsControl(nlsTol=1000, maxIter=1000))
  
  
    compare$preds.new <- as.vector(predict(model.new, newdata = dftest))
    compare$week <- ceiling(as.numeric(format(compare$date, "%j"))/7)
  
    # weekly comparison dataframe
    compare.w <- merge(
      aggregate(preds.new~week+location,FUN=mean,data=compare,
                na.action=na.omit),
      aggregate(water~week+location,FUN=mean,data=compare,
                na.action=na.omit),all=TRUE) %>% na.omit() %>% 
      arrange(location, week)
    
    complist[[loc]][[3]] <- compare.w
    
  # store in results dataframes
  rmse.r[loc,3]=round(sqrt(mean((compare.w$preds.new-compare.w$water)^2)),2)
  bias.r[loc,3]=round(mean(compare.w$preds.new-compare.w$water),2)
  nsc.r[loc,3]=round(1-sum((compare.w$water-compare.w$preds.new)^2) / sum((compare.w$water-mean(compare.w$water))^2),2)
  
  
  ## assumptions
  plot(model.new$residuals~model.new$fitted, main=loc)
  abline(h=0)
  
  
  ## prediction plots
  pl <- ggplot(data=compare.w, aes(x=week))+
          geom_line(aes(x=week, y=water), color = "black")+
          geom_line(aes(x=week, y=preds.new), color = "blue")+
          ggtitle(paste(
            loc, ": (RMSE:", rmse.r[loc,3], "&", "bias:",
            bias.r[loc,3], ")"))
  print(pl)
  
  
  ## get coefs
  for (c in 1:3){coef.nonl[loc,c]=signif(coef(model.new)[c],2)}
}
```



## SECTION 4: Compare REGIONAL and GLOBAL

### Global futureStream database

We import weekly modeled water temperature data from the 14 tributary locations.

```{r futureStreams data import}
## Import the futureStreams modeled WT
futurestreams.temp <- read.csv("futureS modeled water temperature.csv") %>% 
  rename(preds.futureS = modeled.temp) %>% 
  arrange(location, year, week)
```


### Combine REGIONAL and GLOBAL into one file

```{r get futureStreams weekly output}
## Get future dataframe years and weeks
future.w <- merge(futurestreams.temp, y,
                  by.x = c("location","year"),
                  by.y = c("loc_seq","ytest")) %>% 
  filter(week >= 14 & week <= 29) %>% 
  arrange(location, week)
#' we are using data from Julian day 90-200, this is week 13-29


## Calculate performance metrics
for (loc in loc_seq) {

  compare.w <- merge(future.w[future.w$location == loc,],
                     complist[[loc]][[2]], # use seasonal output
                     by=c("location","week"))
  
  complist[[loc]][[4]] <- compare.w
  
  rmse.r[loc,4]=round(sqrt(mean((compare.w$preds.futureS-compare.w$water)^2)),2)
  bias.r[loc,4]=round(mean(compare.w$preds.futureS-compare.w$water),2)
  nsc.r[loc,4]=round(1-sum((compare.w$water-compare.w$preds.futureS)^2) / sum((compare.w$water-mean(compare.w$water))^2),2)
}
```


### Plot for comparison

```{r plots}

plot.df1 = complist[["vermilion"]][[4]]
plot.df2 = complist[["stlouis"]][[4]]


diff1.r <- round(sqrt(mean((plot.df1$preds.ar-plot.df1$water)^2)),2)
diff1.g <- round(sqrt(mean((plot.df1$preds.futureS-plot.df1$water)^2)),2)
diff2.r <- round(sqrt(mean((plot.df2$preds.ar-plot.df2$water)^2)),2)
diff2.g <- round(sqrt(mean((plot.df2$preds.futureS-plot.df2$water)^2)),2)

ggplot(data=plot.df1, aes(x=week))+
  geom_line(aes(x=week, y=water), color = "black")+
  geom_line(aes(x=week, y=preds.ar), color = "blue")+
  geom_line(aes(x=week, y=preds.futureS), color = "red")+
  ggtitle(paste(
    plot.df1$location, " (RMSE: regional =", diff1.r, ";",
    "global =", diff1.g, ")"))

ggplot(data=plot.df2, aes(x=week))+
  geom_line(aes(x=week, y=water), color = "black")+
  geom_line(aes(x=week, y=preds.ar), color = "blue")+
  geom_line(aes(x=week, y=preds.futureS), color = "red")+
  ggtitle(paste(
    plot.df2$location, " (RMSE: regional =", diff2.r, ";",
    "global =", diff2.g, ")"))
```



### Write results into csv files

```{r write csv, eval=FALSE}
write.csv(rmse.r, file="RMSE for plot.csv")
write.csv(bias.r, file="bias for plot.csv")
write.csv(nsc.r, file="NSC for plot.csv")
```